//Convert the user's query to embeddings, retrieve relevant chunks, and prepare the input for the LLM.
def handle_query(query, index, metadata_path="metadata.json"):
    # Convert query to embedding
    query_embedding = embedding_model.encode([query])
    
    # Perform similarity search in FAISS index
    k = 5
    distances, indices = index.search(query_embedding, k)
    
    # Load metadata to map results
    with open(metadata_path, "r") as f:
        metadata = json.load(f)
    
    relevant_chunks = [metadata[idx]['chunk'] for idx in indices[0]]
    return relevant_chunks

# Example: Query the system
query = "What is the mission statement of the website?"
relevant_data = handle_query(query, vector_index)
print(relevant_data)
